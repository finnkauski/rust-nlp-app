# Generate text using GPT2 ðŸ¤– 

<p align="center"><img align="center" src="./demo.png" width="400px"></p>

This repo has code that builds a simple web app and allows end-users to provide a prompt that then is used by GPT2 to generate an output. 

In general, this is quite slow on my machine as I have my GPU disabled. This is a good example repo for me in case I want to build similar `transformer` based apps in future. It uses [rust-bert](https://docs.rs/rust-bert/0.7.11/rust_bert/) as the core of NLP models and you can swap out bits for other bits and build a more fun set of examples. 
